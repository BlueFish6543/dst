decode:
  model_name_or_path: 'google/t5-v1_1-base'
  max_seq_len: 1024 # maximum sequence length of inputs
  data_size: -1 # how many examples to decode
  decode_only: [] # which dialogue IDs to decode
  # This field is only used if the decoding command is run with --all flag.
  decode_steps: []
  max_len: 1024 # maximum sequence length to be generated before <EOS>
  temperature: 1.0
  num_beams: 1
  # Path where the hypothesis files are saved.
  # Will be suffixed by model binary file name (aka checkpoint.split("/")[-1]. Can be overridden via -hyp/--hyp_path.
  hyp_dir: '/scratches/neuron/dev/d3st/hyps'
  # Subdirectory in hyp_dir where files are to be saved
  experiment_name: 'pegasus_schema_aug'
  # If set to `huggingface', calls Hugging Face API during decoding for generation. Might fail by predicting same
  # token repeatedly and failing to predict <EOS>. All subsequent calls to the API fail. If this happens set the
  # flag to `custom'
  generate_api: 'huggingface'
  # Maxinum number of tokens repeated consecutively. Only used when for generate_api is `custom'
  repeat_token_tolerance: 15
  verbose:
    disable_display: false

reproduce:
  seed: 20220303 # same seed for random, NumPy, PyTorch (CPU/GPU), across devices.
  cudnn:
    enabled: True
    deterministic: False
    benchmark: True
