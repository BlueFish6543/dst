data:
  # This is updated at runtime based on data version provided in CLI
  version: -1
  preprocessing: {}

train:
  model_name_or_path: 'google/t5-v1_1-base'
  max_seq_len: 1024 # maximum sequence length
  epochs: 9 # maximum number of epochs
  data_size: -1 # number of examples in an epoch (-1: all examples available); use for testing
  batch_size: 4
  gradient_accumulation_steps: 8 # gradients applied every this many batches to the output
  max_grad_norm: 1.0
  use_scheduler: false
  warmup_steps: 0
  learning_rate: 1e-4
  adam_eps: 1e-7
  fp16: false # use float16 in training
  eps: 1e-12
  # Path where checkpoints are *saved*
  checkpoint_dir: 'models'
  # If populated, the checkpoints are saved under checkpoint_dir/experiment_name
  experiment_name: 'pegasus_schema_aug'
  # Populate if the training is restarted from checkpoint
  checkpoint: ''
  verbose:
    disable_display: false
  data_parallel: false

dev:
  model_name_or_path: 'google/t5-v1_1-base'
  max_seq_len: 1024 # maximum sequence length
  data_size: -1 # number of examples in an epoch (-1: all examples available); use for testing
  eval_interval: 66000 # number of examples after which the model is evaluated
  batch_size: 8
  verbose:
    disable_display: false

reproduce:
  seed: 20220303 # same seed for random, NumPy, PyTorch (CPU/GPU), across devices
  cudnn:
    enabled: True
    deterministic: False
    benchmark: True
