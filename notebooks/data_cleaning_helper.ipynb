{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b904326",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import logging \n",
    "import sys\n",
    "\n",
    "from collections import defaultdict\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "from typing import Union, Callable, Optional\n",
    "from itertools import repeat\n",
    "logging.basicConfig(level=logging.INFO, stream=sys.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94990ab4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data loading utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "219cfa7f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def nested_defaultdict(default_factory: Callable, depth: int = 1):\n",
    "    \"\"\"Creates a nested default dictionary of arbitrary depth with a specified callable as leaf.\"\"\"\n",
    "    if not depth:\n",
    "        return default_factory()\n",
    "    result = partial(defaultdict, default_factory)\n",
    "    for _ in repeat(None, depth - 1):\n",
    "        result = partial(defaultdict, result)\n",
    "    return result()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5d8a17",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Tensorboard parsing utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3683aa",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Parse the losses from tensorboard and process into a dictionary for each experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e947c21f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorboard as tb\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b15193d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def safeget(dct: dict, *keys: Union[tuple[str], list[str]]):\n",
    "    \"\"\"Retrieves the value of one nested key represented in `keys`\"\"\"\n",
    "    for key in keys:\n",
    "        try:\n",
    "            dct = dct[key]\n",
    "        except KeyError:\n",
    "            return None\n",
    "    return dct\n",
    "\n",
    "def parse_tb_to_df(experiment_id: str) -> pd.DataFrame:\n",
    "    experiment = tb.data.experimental.ExperimentFromDev(experiment_id)\n",
    "    return experiment.get_scalars()\n",
    "\n",
    "def get_version(exp_name: str) -> str:\n",
    "    match = re.search(r\"version_\\d+$\", exp_name)  # noqa\n",
    "    if match is not None:\n",
    "          version = exp_name[match.start() : match.end()]\n",
    "    else:\n",
    "        logging.warning(\n",
    "               f\"Experiment name {exp_name} contained no input data version, defaulting to version_1\"\n",
    "        )\n",
    "        version = \"version_1\"\n",
    "    return version\n",
    "\n",
    "\n",
    "def map_tb_df_to_dict(\n",
    "        df: pd.DataFrame,\n",
    "        experiment_name_map: Optional[dict[str, str]] = None,\n",
    "        tag_name_map: Optional[dict[str, str]] = None,\n",
    "        include_version: bool = True,\n",
    "        include_only_tags: Optional[set[str]] = None,\n",
    "        extrema_functions: Optional[Union[Callable, list[Callable]]] = None,\n",
    ") -> dict:\n",
    "    # group_df = nested_defaultdict(list, depth=2)\n",
    "    depth = 3 if not include_version else 4\n",
    "    tag_values = nested_defaultdict(list, depth=depth)\n",
    "    extrema_indices = nested_defaultdict(list, depth=depth)\n",
    "    time_series_keys = [\"step\", \"value\"]\n",
    "    ver = None\n",
    "    get_extremum = min\n",
    "    if callable(extrema_functions):\n",
    "        get_extremum = extrema_functions\n",
    "    for exp_name, exp_df in df.groupby(df.run):\n",
    "        if experiment_name_map is not None and exp_name in experiment_name_map:\n",
    "            exp_name = experiment_name_map[exp_name]\n",
    "        if include_version:\n",
    "            ver = get_version(exp_name)\n",
    "        for tag_name, tag_df in exp_df.groupby(exp_df.tag):\n",
    "            if include_only_tags is not None and not any((tag in tag_name for tag in include_only_tags)):\n",
    "                continue\n",
    "            tag_name = tag_name.replace(\"Loss/\", \"\")\n",
    "            if tag_name_map is not None and tag_name in tag_name_map:\n",
    "                tag_name = tag_name_map[tag_name]\n",
    "            store_location_prefix = [\n",
    "                exp_name if ver is None else exp_name.replace(f\"_{ver}\", \"\"),\n",
    "                tag_name\n",
    "            ]\n",
    "            for step_or_value in time_series_keys:\n",
    "                if ver is not None:\n",
    "                    store_key = store_location_prefix + [ver, step_or_value]\n",
    "                    store_location = safeget(tag_values, *store_key)\n",
    "                    extrema_store_location = safeget(extrema_indices, *store_key)\n",
    "                else:\n",
    "                    store_key = store_location_prefix + [step_or_value]\n",
    "                    store_location = safeget(tag_values, *store_key)\n",
    "                    extrema_store_location = safeget(extrema_indices, *store_key)\n",
    "                series = tag_df[step_or_value].tolist()\n",
    "                store_location.extend(series)\n",
    "                if step_or_value == 'value':\n",
    "                    if isinstance(extrema_functions, list):\n",
    "                        assert include_only_tags is not None\n",
    "                        assert len(extrema_functions) == len(include_only_tags)\n",
    "                        get_extremum = extrema_functions[tag_name.index(include_only_tags)]\n",
    "                    extremum = get_extremum(series)\n",
    "                    extremum_index = series.index(extremum)\n",
    "                    extremum_step = tag_df[\"step\"].tolist()[extremum_index]\n",
    "                    extrema_store_location.append(extremum_step)\n",
    "                    step_store_key = store_key[:-1] + ['step']\n",
    "                    step_store_location = safeget(extrema_indices, *step_store_key)\n",
    "                    step_store_location.append(extremum_index)\n",
    "\n",
    "            # group_df[exp_name][tag_name] = tag_df\n",
    "            # loss_values[exp_name][tag_name][\"step\"] = tag_df.step.tolist()\n",
    "            # loss_values[exp_name][tag_name][\"value\"] = tag_df.value.tolist()\n",
    "    return {\n",
    "        'series_values': tag_values,\n",
    "        'extrema': extrema_indices,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a815647c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Parse tensorboard and find the step at which #ALL_SERVICES/joint_goal_accuracy is maximised. Delete all the other checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "28c610b7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21aa4421",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "experiment_id = 'SWslQNHDRveX06WKof46ZA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "264a8477",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:absl:Requested server info: <version: \"2.8.0\"\n",
      "plugin_specification {\n",
      "  upload_plugins: \"scalars\"\n",
      "}\n",
      ">\n"
     ]
    }
   ],
   "source": [
    "tb_df = parse_tb_to_df(experiment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8f32f7a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:root:Experiment name d3st-v1_1 contained no input data version, defaulting to version_1\n",
      "WARNING:root:Experiment name pegasus_schema_aug contained no input data version, defaulting to version_1\n",
      "WARNING:root:Experiment name seed_240463_d3st_baseline_t5_small_version_7_bs16_ga16_wa125 contained no input data version, defaulting to version_1\n",
      "WARNING:root:Experiment name seed_240463_d3st_baseline_t5_small_version_7_ref contained no input data version, defaulting to version_1\n"
     ]
    }
   ],
   "source": [
    "data = map_tb_df_to_dict(\n",
    "    tb_df, \n",
    "    include_only_tags = {'#ALL_SERVICES/joint_goal_accuracy'},\n",
    "    extrema_functions = max,\n",
    "\n",
    ")\n",
    "series = data['series_values']\n",
    "extrema = data['extrema']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0f346c02",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "keyword = 't5_small'\n",
    "metric = '#ALL_SERVICES/joint_goal_accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f407b621",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "matching_keys = [k for k in data['extrema'].keys() if keyword in k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d030f43c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed_230792_d3st_baseline_t5_small_bs_16_ga_4_wa_500 version_7 dict_keys(['step', 'value']) ; step [12] ; value [2080000]\n",
      "seed_230792_d3st_baseline_t5_small version_7 dict_keys(['step', 'value']) ; step [15] ; value [2560000]\n",
      "seed_240463_d3st_baseline_t5_small_bs_16_ga_4_wa_500 version_7 dict_keys(['step', 'value']) ; step [21] ; value [3520000]\n",
      "seed_240463_d3st_baseline_t5_small_bs_16_ga_{$.gradient_accumulation_steps}_wa_500 version_7 dict_keys(['step', 'value']) ; step [15] ; value [2560000]\n",
      "seed_240463_d3st_baseline_t5_small version_7 dict_keys(['step', 'value']) ; step [15] ; value [2880000]\n",
      "seed_240463_d3st_baseline_t5_small_version_7_bs16_ga16_wa125 version_1 dict_keys(['step', 'value']) ; step [14] ; value [2400000]\n",
      "seed_240463_d3st_baseline_t5_small_version_7_ref version_1 dict_keys(['step', 'value']) ; step [13] ; value [2240000]\n"
     ]
    }
   ],
   "source": [
    "for mk in matching_keys:\n",
    "    metric_data = data['extrema'][mk][metric]\n",
    "    version_keys = metric_data.keys()\n",
    "    for vk in version_keys:\n",
    "        print(mk, vk, metric_data[vk].keys(),\"; step\", metric_data[vk]['step'], \"; value\", metric_data[vk]['value'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1ab3439e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "models_path = Path('/scratches/neuron/dev/d3st/models')\n",
    "version =7\n",
    "pattern = re.compile(r'model\\.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bda71074",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discard /scratches/neuron/dev/d3st/models/seed_230792_d3st_baseline_t5_small_bs_16_ga_4_wa_500/version_7/model.160000\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'shutil' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [41]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m      8\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdiscard \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmdir\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 9\u001B[0m     \u001B[43mshutil\u001B[49m\u001B[38;5;241m.\u001B[39mrmtree(mdir)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'shutil' is not defined"
     ]
    }
   ],
   "source": [
    "for mk in matching_keys:\n",
    "    for mdir in models_path.joinpath(mk, f\"version_{version}\").iterdir():\n",
    "        if pattern.match(mdir.name):\n",
    "            max_jga_step = data['extrema'][mk][metric][f\"version_{version}\"][\"value\"][0]\n",
    "            if mdir.name == f\"model.{max_jga_step}\":\n",
    "                print(f\"keep {mdir}\")\n",
    "            else:\n",
    "                print(f\"discard {mdir}\")\n",
    "                shutil.rmtree(mdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d84caef",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ec9ed1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac8e72c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bbe05a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b86a47",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2c1b35",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35098734",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e88921",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5717199e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b7c52f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0ced50",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ed4a8b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
